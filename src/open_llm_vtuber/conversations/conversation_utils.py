import asyncio
import re
from typing import Optional, Union, Any, List, Dict
import numpy as np
import json
from loguru import logger

from ..message_handler import message_handler
from .types import WebSocketSend, BroadcastContext
from .tts_manager import TTSTaskManager
from ..agent.output_types import SentenceOutput, AudioOutput
from ..agent.input_types import BatchInput, TextData, ImageData, TextSource, ImageSource
from ..asr.asr_interface import ASRInterface
from ..live2d_model import Live2dModel
from ..tts.tts_interface import TTSInterface
from ..utils.stream_audio import prepare_audio_payload


# Convert class methods to standalone functions
async def create_batch_input(
    input_text: str,
    images: Optional[List[Dict[str, Any]]],
    from_name: str,
    metadata: Optional[Dict[str, Any]] = None,
    kb_manager=None,
    conf_uid: Optional[str] = None,
    kb_config=None,
) -> tuple[BatchInput, Optional[List[Dict]]]:
    """
    Create batch input for agent processing with optional KB retrieval.

    Returns:
        Tuple of (BatchInput, Optional RAG results list)
    """
    texts = [TextData(source=TextSource.INPUT, content=input_text, from_name=from_name)]
    rag_results = None  # Store RAG results for frontend display

    # Inject KB context if enabled
    logger.debug(
        f"ğŸ“š KB check - manager={kb_manager is not None}, conf_uid={conf_uid}, config={kb_config}, enabled={kb_config.enabled if kb_config else 'N/A'}"
    )

    if kb_manager and conf_uid and kb_config and kb_config.enabled:
        try:
            logger.info(
                f"ğŸ” KB RAG enabled - retrieving context for query: '{input_text[:100]}...'"
            )
            logger.info(
                f"ğŸ” KB params: top_k={kb_config.top_k}, max_chars={kb_config.max_context_chars}"
            )

            results = await kb_manager.retrieve(
                conf_uid=conf_uid,
                query=input_text,
                top_k=kb_config.top_k,
                max_chars=kb_config.max_context_chars,
            )

            if results:
                formatted_context = await kb_manager.format_retrieved_context(results)
                texts.insert(
                    0,  # Add at the beginning as context
                    TextData(
                        source=TextSource.KB_CONTEXT,
                        content=formatted_context,
                        from_name=None,
                    ),
                )
                # Store RAG results for frontend display
                rag_results = results
                logger.info(
                    f"âœ… KB RAG: Injected {len(results)} results ({len(formatted_context)} chars) into context"
                )
            else:
                logger.info("ğŸ“š KB RAG: No results found for query")
        except Exception as e:
            logger.error(f"âŒ KB RAG failed: {e}")
            import traceback

            logger.error(traceback.format_exc())
    else:
        if not kb_manager:
            logger.debug("ğŸ“š KB RAG skipped: No KB manager")
        elif not conf_uid:
            logger.debug("ğŸ“š KB RAG skipped: No conf_uid")
        elif not kb_config:
            logger.debug("ğŸ“š KB RAG skipped: No KB config")
        elif not kb_config.enabled:
            logger.debug("ğŸ“š KB RAG skipped: KB disabled in config")

    # Inject daily schedule as context if present
    if metadata and "daily_schedule" in metadata:
        daily_schedule_text = metadata["daily_schedule"]
        if daily_schedule_text and daily_schedule_text.strip():
            texts.insert(
                0,  # Add at the beginning as context
                TextData(
                    source=TextSource.DAILY_SCHEDULE,
                    content=daily_schedule_text,
                    from_name=None,
                ),
            )

    # Inject countdown target as context if present
    if metadata and "countdown_target" in metadata:
        countdown_text = metadata["countdown_target"]
        if countdown_text and str(countdown_text).strip():
            texts.insert(
                0,  # Add at the beginning as context
                TextData(
                    source=TextSource.COUNTDOWN_TARGET,
                    content=str(countdown_text),
                    from_name=None,
                ),
            )

    batch_input = BatchInput(
        texts=texts,
        images=[
            ImageData(
                source=ImageSource(img["source"]),
                data=img["data"],
                mime_type=img["mime_type"],
            )
            for img in (images or [])
        ]
        if images
        else None,
        metadata=metadata,
    )

    return batch_input, rag_results


async def process_agent_output(
    output: Union[AudioOutput, SentenceOutput],
    character_config: Any,
    live2d_model: Live2dModel,
    tts_engine: TTSInterface,
    websocket_send: WebSocketSend,
    tts_manager: TTSTaskManager,
    translate_engine: Optional[Any] = None,
) -> str:
    """Process agent output with character information and optional translation"""
    output.display_text.name = character_config.character_name
    output.display_text.avatar = character_config.avatar

    full_response = ""
    try:
        if isinstance(output, SentenceOutput):
            full_response = await handle_sentence_output(
                output,
                live2d_model,
                tts_engine,
                websocket_send,
                tts_manager,
                translate_engine,
            )
        elif isinstance(output, AudioOutput):
            full_response = await handle_audio_output(output, websocket_send)
        else:
            logger.warning(f"Unknown output type: {type(output)}")
    except Exception as e:
        logger.error(f"Error processing agent output: {e}")
        await websocket_send(
            json.dumps(
                {"type": "error", "message": f"Error processing response: {str(e)}"}
            )
        )

    return full_response


async def handle_sentence_output(
    output: SentenceOutput,
    live2d_model: Live2dModel,
    tts_engine: TTSInterface,
    websocket_send: WebSocketSend,
    tts_manager: TTSTaskManager,
    translate_engine: Optional[Any] = None,
) -> str:
    """Handle sentence output type with optional translation support"""
    full_response = ""
    async for display_text, tts_text, actions in output:
        logger.debug(f"ğŸƒ Processing output: '''{tts_text}'''...")

        if translate_engine:
            if len(re.sub(r'[\s.,!?ï¼Œã€‚ï¼ï¼Ÿ\'"ã€ã€ï¼‰ã€‘\s]+', "", tts_text)):
                tts_text = translate_engine.translate(tts_text)
            logger.info(f"ğŸƒ Text after translation: '''{tts_text}'''...")
        else:
            logger.debug("ğŸš« No translation engine available. Skipping translation.")

        full_response += display_text.text
        await tts_manager.speak(
            tts_text=tts_text,
            display_text=display_text,
            actions=actions,
            live2d_model=live2d_model,
            tts_engine=tts_engine,
            websocket_send=websocket_send,
        )
    return full_response


async def handle_audio_output(
    output: AudioOutput,
    websocket_send: WebSocketSend,
) -> str:
    """Process and send AudioOutput directly to the client"""
    full_response = ""
    async for audio_path, display_text, transcript, actions in output:
        full_response += transcript
        audio_payload = prepare_audio_payload(
            audio_path=audio_path,
            display_text=display_text,
            actions=actions.to_dict() if actions else None,
        )
        await websocket_send(json.dumps(audio_payload))
    return full_response


async def send_conversation_start_signals(websocket_send: WebSocketSend) -> None:
    """Send initial conversation signals"""
    await websocket_send(
        json.dumps(
            {
                "type": "control",
                "text": "conversation-chain-start",
            }
        )
    )
    await websocket_send(json.dumps({"type": "full-text", "text": "Thinking..."}))


async def process_user_input(
    user_input: Union[str, np.ndarray],
    asr_engine: ASRInterface,
    websocket_send: WebSocketSend,
) -> str:
    """Process user input, converting audio to text if needed"""
    if isinstance(user_input, np.ndarray):
        logger.info("Transcribing audio input...")
        input_text = await asr_engine.async_transcribe_np(user_input)
        await websocket_send(
            json.dumps({"type": "user-input-transcription", "text": input_text})
        )
        return input_text
    return user_input


async def finalize_conversation_turn(
    tts_manager: TTSTaskManager,
    websocket_send: WebSocketSend,
    client_uid: str,
    broadcast_ctx: Optional[BroadcastContext] = None,
) -> None:
    """Finalize a conversation turn"""
    if tts_manager.task_list:
        await asyncio.gather(*tts_manager.task_list)
        await websocket_send(json.dumps({"type": "backend-synth-complete"}))

        response = await message_handler.wait_for_response(
            client_uid, "frontend-playback-complete"
        )

        if not response:
            logger.warning(f"No playback completion response from {client_uid}")
            return

    await websocket_send(json.dumps({"type": "force-new-message"}))

    if broadcast_ctx and broadcast_ctx.broadcast_func:
        await broadcast_ctx.broadcast_func(
            broadcast_ctx.group_members,
            {"type": "force-new-message"},
            broadcast_ctx.current_client_uid,
        )

    await send_conversation_end_signal(websocket_send, broadcast_ctx)


async def send_conversation_end_signal(
    websocket_send: WebSocketSend,
    broadcast_ctx: Optional[BroadcastContext],
    session_emoji: str = "ğŸ˜Š",
) -> None:
    """Send conversation chain end signal"""
    chain_end_msg = {
        "type": "control",
        "text": "conversation-chain-end",
    }

    await websocket_send(json.dumps(chain_end_msg))

    if broadcast_ctx and broadcast_ctx.broadcast_func and broadcast_ctx.group_members:
        await broadcast_ctx.broadcast_func(
            broadcast_ctx.group_members,
            chain_end_msg,
        )

    logger.info(f"ğŸ˜ğŸ‘âœ… Conversation Chain {session_emoji} completed!")


def cleanup_conversation(tts_manager: TTSTaskManager, session_emoji: str) -> None:
    """Clean up conversation resources"""
    tts_manager.clear()
    logger.debug(f"ğŸ§¹ Clearing up conversation {session_emoji}.")


EMOJI_LIST = [
    "ğŸ¶",
    "ğŸ±",
    "ğŸ­",
    "ğŸ¹",
    "ğŸ°",
    "ğŸ¦Š",
    "ğŸ»",
    "ğŸ¼",
    "ğŸ¨",
    "ğŸ¯",
    "ğŸ¦",
    "ğŸ®",
    "ğŸ·",
    "ğŸ¸",
    "ğŸµ",
    "ğŸ”",
    "ğŸ§",
    "ğŸ¦",
    "ğŸ¤",
    "ğŸ£",
    "ğŸ¥",
    "ğŸ¦†",
    "ğŸ¦…",
    "ğŸ¦‰",
    "ğŸ¦‡",
    "ğŸº",
    "ğŸ—",
    "ğŸ´",
    "ğŸ¦„",
    "ğŸ",
    "ğŸŒµ",
    "ğŸ„",
    "ğŸŒ²",
    "ğŸŒ³",
    "ğŸŒ´",
    "ğŸŒ±",
    "ğŸŒ¿",
    "â˜˜ï¸",
    "ğŸ€",
    "ğŸ‚",
    "ğŸ",
    "ğŸ„",
    "ğŸŒ¾",
    "ğŸ’",
    "ğŸŒ¹",
    "ğŸŒ¸",
    "ğŸŒ›",
    "ğŸŒ",
    "â­ï¸",
    "ğŸ”¥",
    "ğŸŒˆ",
    "ğŸŒ©",
    "â›„ï¸",
    "ğŸƒ",
    "ğŸ„",
    "ğŸ‰",
    "ğŸ",
    "ğŸ—",
    "ğŸ€„ï¸",
    "ğŸ­",
    "ğŸ¨",
    "ğŸ§µ",
    "ğŸª¡",
    "ğŸ§¶",
    "ğŸ¥½",
    "ğŸ¥¼",
    "ğŸ¦º",
    "ğŸ‘”",
    "ğŸ‘•",
    "ğŸ‘œ",
    "ğŸ‘‘",
]
